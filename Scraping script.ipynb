{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "73alQKQ4l1aY"
   },
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from pytubefix import Search, YouTube\n",
    "import whisper\n",
    "import torch\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apzrdQCNl1aZ",
    "outputId": "8c06c630-c68c-4d39-966c-6fc4c276a8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\prog apps\\python\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Whisper model and check for CUDA support\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "model = whisper.load_model(\"turbo\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TmbpsaCIl1aa"
   },
   "outputs": [],
   "source": [
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to SRT timestamp format (HH:MM:SS,mmm)\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    millisecs = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WILPFtakl1aa"
   },
   "outputs": [],
   "source": [
    "def transcribe_with_whisper(video_title, model, language=\"en\"):\n",
    "    # Transcription function with SRT output\n",
    "    result = model.transcribe(\n",
    "        f\"audio/{video_title}.wav\",\n",
    "        language=language,  # Language specified in global variable\n",
    "        task=\"transcribe\",\n",
    "        fp16=torch.cuda.is_available(),  # Use float16 if on GPU\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Extract the segments with timestamps and text\n",
    "    segments = result[\"segments\"]\n",
    "\n",
    "    \"\"\"Generate SRT formatted content from transcript segments\"\"\"\n",
    "    srt_parts = []\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        start = format_timestamp(segment[\"start\"])\n",
    "        end = format_timestamp(segment[\"end\"])\n",
    "        text = segment[\"text\"].strip()\n",
    "        srt_parts.append(f\"{i}\\n{start} --> {end}\\n{text}\\n\")\n",
    "    srt_transcription = \"\\n\".join(srt_parts)\n",
    "\n",
    "    # Remove the trailing newline after the last subtitle (to avoid extra blank line)\n",
    "    srt_transcription = srt_transcription.strip()\n",
    "\n",
    "    # Save the SRT transcription to a file\n",
    "    transcription_path = f\"whisper_captions/{video_title}.srt\"\n",
    "    with open(transcription_path, \"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(srt_transcription)  # Write without extra newlines\n",
    "\n",
    "    print(f\"SRT transcription generated with Whisper for {video_title}.\")\n",
    "    return transcription_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-fS1smiGl1aa"
   },
   "outputs": [],
   "source": [
    "def download_audio_and_transcription(query, num_videos=1, language=\"en\"):\n",
    "    # Ensure necessary directories exist\n",
    "    os.makedirs(\"audio\", exist_ok=True)\n",
    "    os.makedirs(\"YT_captions\", exist_ok=True)\n",
    "    os.makedirs(\"whisper_captions\", exist_ok=True)\n",
    "\n",
    "\n",
    "    # Search for the video\n",
    "    search = Search(query)\n",
    "    videos = search.videos  # Use .videos instead of .results\n",
    "\n",
    "    if not videos:\n",
    "        print(\"No videos found for query.\")\n",
    "        return\n",
    "\n",
    "    processed_count = 0 # number of processed videos\n",
    "    i = 0  # Index for the video list\n",
    "\n",
    "    # Iterate until we process the required number of videos\n",
    "    while processed_count < num_videos:\n",
    "        if i >= len(videos):  # If there are not enough videos, fetch more results\n",
    "          search.get_next_results()\n",
    "          videos = search.videos\n",
    "          i = 0  # Reset the index for the new video list\n",
    "\n",
    "\n",
    "        video = videos[i]\n",
    "        yt = YouTube(video.watch_url)\n",
    "        video_url = video.watch_url\n",
    "        \n",
    "        # Sanitize video title to use as filename\n",
    "        video_title = re.sub(r\"[^\\w]\", \"_\", video.title)\n",
    "        audio_path = f\"audio/{video_title}.wav\"\n",
    "\n",
    "        # Check if the video length is within the desired range (5 to 15 minutes)\n",
    "        video_length = yt.length / 60  # Convert seconds to minutes\n",
    "        if video_length < 5 or video_length > 25:\n",
    "            print(f\"Skipping video '{yt.title}' (Length: {int(video_length)} minutes)\")\n",
    "            i += 1  # Move to the next video\n",
    "            continue\n",
    "\n",
    "        # check of the audio file already exists\n",
    "        if os.path.exists(audio_path):\n",
    "            print(f\"Audio for '{video_title}' already exists. Skipping download.\")\n",
    "            i += 1 # Move to the next video\n",
    "            continue\n",
    "\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': f\"audio/{video_title}.%(ext)s\",  # Adjust the template to avoid double extensions\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'wav',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'quiet': True,\n",
    "        }\n",
    "\n",
    "\n",
    "        # Download the audio\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            print(f\"Downloading audio for {video_title}...\")\n",
    "            ydl.download([video_url])\n",
    "\n",
    "        # Check for YouTube transcription\n",
    "        captions = video.captions\n",
    "        if captions:\n",
    "            for lang in captions:\n",
    "                if lang.code == language:\n",
    "                    transcript = lang.generate_srt_captions()\n",
    "                    transcription_path = f\"YT_captions/{video_title}.srt\"\n",
    "                    with open(transcription_path, \"w\",encoding=\"utf-8\") as f:\n",
    "                        f.write(transcript)\n",
    "                    print(f\"Downloaded YouTube transcription for {video_title}.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No language transcription available for {video_title}, generating with Whisper...\")\n",
    "                transcription_path = transcribe_with_whisper(video_title, model, language)\n",
    "        else:\n",
    "            print(f\"No transcription available for {video_title}, generating with Whisper...\")\n",
    "            transcription_path = transcribe_with_whisper(video_title, model, language)\n",
    "\n",
    "        print(f\"Audio and transcription saved for {video_title}.\")\n",
    "        processed_count += 1\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Processed {processed_count} videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N_ZY2Z0Sl1ab",
    "outputId": "6c37208f-453c-40e3-ab6d-261dfd1da6cc"
   },
   "outputs": [],
   "source": [
    "# Usage\n",
    "query = \"دروس اونلاين\" # search query on youtube\n",
    "num_videos = 15  # Modify this number to download and transcribe N videos\n",
    "language = \"ar\"  # Language code for YouTube transcription (if available)\n",
    "download_audio_and_transcription(query, num_videos, language)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from pytubefix import Search\n",
    "import whisper\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time_to_srt(seconds):\n",
    "    \"\"\"Helper function to convert time in seconds to SRT format (HH:MM:SS,MS)\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_whisper(audio_path, model):\n",
    "    # Transcription function with SRT output\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        language=\"en\",  # Language specified in global variable\n",
    "        task=\"transcribe\",\n",
    "        fp16=torch.cuda.is_available()  # Use float16 if on GPU\n",
    "    )\n",
    "\n",
    "    # Extract the segments with timestamps and text\n",
    "    segments = result[\"segments\"]\n",
    "\n",
    "    # Prepare the SRT formatted transcription\n",
    "    srt_transcription = \"\"\n",
    "    for i, segment in enumerate(segments, 1):\n",
    "        start_time = segment[\"start\"]\n",
    "        end_time = segment[\"end\"]\n",
    "        text = segment[\"text\"]\n",
    "        \n",
    "        # Convert times from seconds to SRT format (HH:MM:SS,MS)\n",
    "        start_time_srt = format_time_to_srt(start_time)\n",
    "        end_time_srt = format_time_to_srt(end_time)\n",
    "        \n",
    "        # Append each segment in SRT format (ensuring correct spacing)\n",
    "        srt_transcription += f\"{i}\\n{start_time_srt} --> {end_time_srt}\\n{text}\\n\\n\"\n",
    "\n",
    "    # Remove the trailing newline after the last subtitle (to avoid extra blank line)\n",
    "    srt_transcription = srt_transcription.strip()\n",
    "\n",
    "    # Save the SRT transcription to a file\n",
    "    transcription_path = f\"{os.path.splitext(audio_path)[0]}_transcription.srt\"\n",
    "    with open(transcription_path, \"w\") as f:\n",
    "        f.write(srt_transcription)  # Write without extra newlines\n",
    "    \n",
    "    print(f\"SRT transcription generated with Whisper for {audio_path}.\")\n",
    "    return transcription_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio_and_transcription(query, num_videos=1):\n",
    "    # Initialize Whisper model and check for CUDA support\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = whisper.load_model(\"base\", device=device)\n",
    "    \n",
    "    # Search for the video\n",
    "    search = Search(query)\n",
    "    videos = search.videos  # Use .videos instead of .results\n",
    "    if not videos:\n",
    "        print(\"No videos found for query.\")\n",
    "        return\n",
    "    \n",
    "    # Process the first N videos\n",
    "    for i, video in enumerate(videos[:num_videos]):\n",
    "        video_url = video.watch_url\n",
    "        video_title = video.title.replace(\" \", \"_\")\n",
    "\n",
    "        # Download the audio\n",
    "        audio_path = f\"{video_title}.mp3\"\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': f\"{video_title}.%(ext)s\",  # Adjust the template to avoid double extensions\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'quiet': True,\n",
    "        }\n",
    "        \n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            print(f\"Downloading audio for {video_title}...\")\n",
    "            ydl.download([video_url])\n",
    "        \n",
    "        # Check for YouTube transcription\n",
    "        captions = video.captions\n",
    "        if captions:\n",
    "            for lang in captions:\n",
    "                if lang.code == 'en':\n",
    "                    transcript = lang.generate_srt_captions()\n",
    "                    transcription_path = f\"{video_title}_transcription.txt\"\n",
    "                    with open(transcription_path, \"w\") as f:\n",
    "                        f.write(transcript)\n",
    "                    print(f\"Downloaded YouTube transcription for {video_title}.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No English transcription available for {video_title}, generating with Whisper...\")\n",
    "                transcription_path = transcribe_with_whisper(audio_path, model)\n",
    "        else:\n",
    "            print(f\"No transcription available for {video_title}, generating with Whisper...\")\n",
    "            transcription_path = transcribe_with_whisper(audio_path, model)\n",
    "        \n",
    "        print(f\"Audio and transcription saved for {video_title}.\")\n",
    "    \n",
    "    print(f\"Processed {num_videos} videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.miniconda3/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio for The_M4_Mac_Mini_is_Incredible!...\n",
      "Downloaded YouTube transcription for The_M4_Mac_Mini_is_Incredible!.\n",
      "Audio and transcription saved for The_M4_Mac_Mini_is_Incredible!.\n",
      "Downloading audio for M4_Mac_Mini_Review_-_Apple_NAILED_It....\n",
      "No English transcription available for M4_Mac_Mini_Review_-_Apple_NAILED_It., generating with Whisper...\n",
      "SRT transcription generated with Whisper for M4_Mac_Mini_Review_-_Apple_NAILED_It..mp3.\n",
      "Audio and transcription saved for M4_Mac_Mini_Review_-_Apple_NAILED_It..\n",
      "Downloading audio for Introducing_the_all-new_Mac_mini_|_Apple...\n",
      "Downloaded YouTube transcription for Introducing_the_all-new_Mac_mini_|_Apple.\n",
      "Audio and transcription saved for Introducing_the_all-new_Mac_mini_|_Apple.\n",
      "Processed 3 videos.\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "query = \"mac mini\"\n",
    "num_videos = 3  # Modify this number to download and transcribe N videos\n",
    "download_audio_and_transcription(query, num_videos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

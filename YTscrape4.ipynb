{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytube import YouTube\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import whisper\n",
    "import torch\n",
    "\n",
    "from pytubefix import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from pytubefix.cli import on_progress\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to download by bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(query, max_videos=3, output_path='Audio'):\n",
    "    \"\"\"\n",
    "    Downloads audio from YouTube based on a search query.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The search query to find YouTube videos.\n",
    "    max_videos (int, optional): The maximum number of videos to download. Defaults to 3.\n",
    "    output_path (str, optional): The path to save the downloaded audio files. Defaults to 'Audio'.\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'noplaylist': True,\n",
    "        'outtmpl': f'{output_path}/(title)s.%(ext)s',\n",
    "        'quiet': True,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '50',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        print(f\"Downloading {max_videos} audio files: {query}...\")\n",
    "        info_dict = ydl.extract_info(query, download=True)\n",
    "\n",
    "        downloaded_files =[]\n",
    "        for video in info_dict['entries']:\n",
    "            file_path=os.path.join(output_path, video['title'] + '.mp3')\n",
    "            if os.path.exists(file_path):\n",
    "                downloaded_files.append(file_path)\n",
    "                print(f\"Downloaded :{video['title']}\")\n",
    "            else:\n",
    "                print(f\"Failed to download :{video['title']} with path {file_path}\")\n",
    "        return downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m downloaded_audio\u001b[38;5;241m=\u001b[39m\u001b[43mdownload_audio\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#it should download using keywords but try downloading using keywords and resolve the \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#error\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'download_audio' is not defined"
     ]
    }
   ],
   "source": [
    "downloaded_audio=download_audio(\"\")#it should download using keywords but try downloading using keywords and resolve the \n",
    "#error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=zBjJUV-lzHo&pp=ygUMMSBtaW4gdmlkZW9z\"\n",
    "lang = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download the mp3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 1 minute funny videos\n",
      "length: 60\n",
      " ↳ |████████████████████████████████████████████| 100.0%\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d:\\\\UNI\\\\Year 4 Term 1\\\\speech\\\\project\\\\SpeechProject\\\\1 minute funny videos.mp3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = YouTube(url, on_progress_callback = on_progress)\n",
    "print(\"title: \"+yt.title)\n",
    "print(\"length: \"+str(yt.length))\n",
    "\n",
    "ys = yt.streams.get_audio_only()\n",
    "ys.download(mp3=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whisper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_to_srt(audio_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Transcribe audio file using OpenAI's Whisper model and save as SRT file.\n",
    "\n",
    "    Parameters:\n",
    "    audio_path (str): Path to the audio file\n",
    "    output_path (str, optional): Path to save the SRT file. \n",
    "                                 If None, uses audio filename with .srt extension\n",
    "\n",
    "    Returns:\n",
    "    str: Path to the generated SRT file\n",
    "    \"\"\"\n",
    "    # Check if CUDA is available for GPU acceleration\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Determine output path if not provided\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(audio_path)[0] + \".srt\"\n",
    "\n",
    "    # Load the Whisper model (you can choose different sizes: tiny, base, small, medium, large)\n",
    "    print(\"Loading Whisper model...\")\n",
    "    model = whisper.load_model(\"small\", device=device)\n",
    "\n",
    "    # Load and transcribe the audio file\n",
    "    print(\"Transcribing audio...\")\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        language=lang,  # Language specified in global variable\n",
    "        task=\"transcribe\",\n",
    "        fp16=torch.cuda.is_available()  # Use float16 if on GPU\n",
    "    )\n",
    "\n",
    "    # Generate SRT content\n",
    "    srt_content = []\n",
    "    for i, segment in enumerate(result[\"segments\"], 1):\n",
    "        # Convert start and end times to SRT time format\n",
    "        start_time = format_time(segment[\"start\"])\n",
    "        end_time = format_time(segment[\"end\"])\n",
    "        \n",
    "        # Create SRT entry\n",
    "        srt_content.append(str(i))  # Subtitle number\n",
    "        srt_content.append(f\"{start_time} --> {end_time}\")  # Time codes\n",
    "        srt_content.append(segment[\"text\"].strip())  # Subtitle text\n",
    "        srt_content.append(\"\")  # Blank line between entries\n",
    "\n",
    "    # Write SRT file\n",
    "    with open(output_path, 'w', encoding='utf-8') as srt_file:\n",
    "        srt_file.write(\"\\n\".join(srt_content))\n",
    "\n",
    "    print(f\"SRT file saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"\n",
    "    Convert seconds to SRT time format (00:00:00,000)\n",
    "    \n",
    "    Parameters:\n",
    "    seconds (float): Time in seconds\n",
    "\n",
    "    Returns:\n",
    "    str: Formatted time string\n",
    "    \"\"\"\n",
    "    # Convert to milliseconds\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    \n",
    "    # Convert to hours, minutes, seconds\n",
    "    hours, remainder = divmod(int(seconds), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try downloading YouTube Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hashem Ahmed\\AppData\\Local\\Temp\\ipykernel_29368\\3366458486.py:4: DeprecationWarning: Call to deprecated function get_by_language_code (This object can be treated as a dictionary, i.e. captions['en']).\n",
      "  caption = yt.captions.get_by_language_code(lang) # Specify Arabic language\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\prog apps\\python\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio...\n",
      "SRT file saved to: 10 Programmer Stereotypes.txt\n",
      "\n",
      "Transcription:\n",
      "10 Programmer Stereotypes.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    yt = YouTube(url)\n",
    "\n",
    "    caption = yt.captions.get_by_language_code(lang) # Specify Arabic language\n",
    "    caption.save_captions(yt.title+\".srt\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    audio_file = yt.title+\".mp3\"\n",
    "    output_file = yt.title+\".txt\"\n",
    "\n",
    "    try:\n",
    "        transcript = transcribe_audio_to_srt(audio_file, output_file)\n",
    "        print(\"\\nTranscription:\")\n",
    "        print(transcript)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Title: {yt.title}\")\n",
    "print(f\"Length: {yt.length} seconds\")\n",
    "print(f\"Views: {yt.views}\")\n",
    "print(f\"Author: {yt.author}\")\n",
    "print(f\"Publish Date: {yt.publish_date}\")\n",
    "print(f\"Description: {yt.description}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
